# Deep Guard ML Engine

The **Deep Guard ML Engine** is a high-performance, FastAPI-based microservice designed for detecting deepfakes in images and videos. It utilizes a **TensorFlow Lite (TFLite)** model for efficient inference and **OpenCV** for advanced face tracking and extraction.

> **For a detailed technical overview, please refer to the [System Architecture](ARCHITECTURE.md).**

## ğŸš€ Key Features

-   **Deepfake Detection:** Analyzes both singular images and video frames to determine authenticity (Real vs. Fake).
-   **Optimized Video Processing:** Implements sequential frame reading and pre-allocated buffers for 20-30% faster processing.
-   **Batch Image Analysis:** Supports bulk uploading and processing of images.
-   **Smart Face Tracking:** Uses a 3D Face Tracker to ensure consistent face cropping across video frames.
-   **Automated Cleanup:** Background tasks automatically clean up temporary files after processing to manage disk space.
-   **Annotated Reports:** Generates comprehensive ZIP reports containing annotated frames/images and JSON confidence logs.

## ğŸ› ï¸ Tech Stack

| Technology | Purpose |
| :--- | :--- |
| **Python 3.10+** | Core programming language. |
| **FastAPI** | High-performance async web framework for the API. |
| **TensorFlow Lite** | Lightweight, optimized inference engine for the deepfake model. |
| **OpenCV (cv2)** | Computer vision tasks: video reading, face detection, and image manipulation. |
| **NumPy** | High-speed numerical operations for tensor manipulation. |
| **Uvicorn** | ASGI server for running the FastAPI application. |

## ğŸ“‚ Project Structure

```
Deep-Guard-ML-Engine/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Application entry point
â”‚   â”œâ”€â”€ config/              # Configuration settings (constants, paths)
â”‚   â”œâ”€â”€ routes/              # API Endpoints
â”‚   â”‚   â”œâ”€â”€ video_detection.py # /detect/deepfake/video logic
â”‚   â”‚   â””â”€â”€ image_detection.py # /detect/deepfake/images logic
â”‚   â”œâ”€â”€ services/            # Business Logic Services
â”‚   â”‚   â”œâ”€â”€ model.py         # TFLite Inference wrapper
â”‚   â”‚   â”œâ”€â”€ *_preprocessor.py# Image/Video orchestration
â”‚   â”‚   â””â”€â”€ *_saver.py       # File I/O handlers
â”‚   â””â”€â”€ utils/               # Core Utilities
â”‚       â”œâ”€â”€ face_tracker.py  # 3D Face Detection & Tracking
â”‚       â”œâ”€â”€ face_extractor.py# Conservative cropping logic
â”‚       â””â”€â”€ video_processor.py# Optimized video frame reader
â”œâ”€â”€ models/                  # ML Artifacts (TFLite models)
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # Project documentation
```

## âš¡ API Endpoints

### 1. Detect Video Deepfake
**POST** `/detect/deepfake/video`

Analyzes a video file, extracts faces, runs inference, and returns a ZIP report.

-   **Form Data:**
    -   `file`: The video file (`.mp4`, `.avi`, etc).
    -   `frames` (optional, default 50): Number of frames to extract and analyze.
-   **Response:** `application/zip` containing annotated frames and `confidence_report.json`.
-   **Headers:** `X-Average-Confidence`, `X-Video-ID`.

### 2. Detect Image Deepfakes (Batch)
**POST** `/detect/deepfake/images`

Analyzes a batch of uploaded images.

-   **Form Data:**
    -   `files`: List of image files (`.jpg`, `.png`).
-   **Response:** `application/zip` containing annotated images and report.

## âš™ï¸ Installation & Setup

### Prerequisites
-   Python 3.8 - 3.11 (Recommended)
-   **FFmpeg** installed system-wide (for video processing).

### Steps

1.  **Clone the Repository**
    ```bash
    git clone <repo-url>
    cd Deep-Guard-ML-Engine
    ```

2.  **Create Virtual Environment**
    ```bash
    python -m venv .venv
    # Windows:
    .venv\Scripts\activate
    # Mac/Linux:
    source .venv/bin/activate
    ```

3.  **Install Dependencies**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Run the Server**
    ```bash
    uvicorn app.main:app --reload --port 8000
    ```

The API will be available at `http://localhost:8000`. Documentation is available at `http://localhost:8000/docs`.